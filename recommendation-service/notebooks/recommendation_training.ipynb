{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f57b41df",
   "metadata": {},
   "source": [
    "# E-commerce Recommendation System Training\n",
    "## Content-Based Filtering with Advanced Features\n",
    "\n",
    "This notebook trains and evaluates recommendation models for the e-commerce platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn\n",
    "!pip install pymongo python-dotenv\n",
    "!pip install plotly wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19cd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import pymongo\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a19d9f0",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB connection\n",
    "MONGO_URI = \"mongodb://localhost:27017/ecommerce\"  # Update this\n",
    "client = pymongo.MongoClient(MONGO_URI)\n",
    "db = client['ecommerce']\n",
    "\n",
    "# Load products data\n",
    "products_collection = db['products']\n",
    "products_cursor = products_collection.find({})\n",
    "products_data = list(products_cursor)\n",
    "\n",
    "print(f\"Loaded {len(products_data)} products from MongoDB\")\n",
    "print(\"Sample product:\", products_data[0] if products_data else \"No products found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_data = []\n",
    "for product in products_data:\n",
    "    df_data.append({\n",
    "        '_id': str(product['_id']),\n",
    "        'name': product.get('name', ''),\n",
    "        'category': product.get('category', ''),\n",
    "        'subCategory': product.get('subCategory', ''),\n",
    "        'description': product.get('description', ''),\n",
    "        'price': product.get('price', 0),\n",
    "        'sizes': ','.join(product.get('sizes', [])),\n",
    "        'image': product.get('image', []),\n",
    "        'bestseller': product.get('bestseller', False),\n",
    "        'date': product.get('date', datetime.now())\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(df_data)\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab29be",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Total products: {len(df)}\")\n",
    "print(f\"Categories: {df['category'].nunique()}\")\n",
    "print(f\"Subcategories: {df['subCategory'].nunique()}\")\n",
    "print(f\"Price range: {df['price'].min()} - {df['price'].max()}\")\n",
    "print(f\"Bestsellers: {df['bestseller'].sum()}\")\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Category distribution\n",
    "df['category'].value_counts().plot(kind='bar', ax=axes[0,0])\n",
    "axes[0,0].set_title('Products by Category')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Price distribution\n",
    "df['price'].hist(bins=30, ax=axes[0,1])\n",
    "axes[0,1].set_title('Price Distribution')\n",
    "axes[0,1].set_xlabel('Price')\n",
    "\n",
    "# Subcategory distribution\n",
    "df['subCategory'].value_counts().head(10).plot(kind='bar', ax=axes[1,0])\n",
    "axes[1,0].set_title('Top 10 Subcategories')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Bestseller distribution\n",
    "df['bestseller'].value_counts().plot(kind='pie', ax=axes[1,1], autopct='%1.1f%%')\n",
    "axes[1,1].set_title('Bestseller Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f65f38",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f969f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create content features\n",
    "df['content_features'] = (\n",
    "    df['name'].fillna('') + ' ' +\n",
    "    df['category'].fillna('') + ' ' +\n",
    "    df['subCategory'].fillna('') + ' ' +\n",
    "    df['description'].fillna('') + ' ' +\n",
    "    df['sizes'].fillna('')\n",
    ")\n",
    "\n",
    "# Price categories\n",
    "df['price_category'] = pd.cut(df['price'], \n",
    "                             bins=[0, 100000, 300000, 500000, float('inf')],\n",
    "                             labels=['Budget', 'Mid-range', 'Premium', 'Luxury'])\n",
    "\n",
    "print(\"Sample content features:\")\n",
    "print(df[['name', 'content_features']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51452ff6",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=1,\n",
    "    max_df=0.8\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(df['content_features'])\n",
    "print(f\"TF-IDF Matrix shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"Number of features: {len(feature_names)}\")\n",
    "print(\"Sample features:\", feature_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print(f\"Cosine similarity matrix shape: {cosine_sim.shape}\")\n",
    "\n",
    "# Visualize similarity distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(cosine_sim.flatten(), bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Cosine Similarities')\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean similarity: {cosine_sim.mean():.4f}\")\n",
    "print(f\"Std similarity: {cosine_sim.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2788f8f",
   "metadata": {},
   "source": [
    "## 5. Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(product_id, num_recommendations=5):\n",
    "    \"\"\"Get product recommendations based on content similarity\"\"\"\n",
    "    try:\n",
    "        # Find product index\n",
    "        product_idx = df[df['_id'] == product_id].index\n",
    "        if len(product_idx) == 0:\n",
    "            return []\n",
    "        \n",
    "        product_idx = product_idx[0]\n",
    "        \n",
    "        # Get similarity scores\n",
    "        sim_scores = cosine_sim[product_idx]\n",
    "        \n",
    "        # Get similar products (excluding the product itself)\n",
    "        similar_indices = sim_scores.argsort()[::-1][1:num_recommendations+1]\n",
    "        \n",
    "        recommendations = []\n",
    "        for idx in similar_indices:\n",
    "            product = df.iloc[idx]\n",
    "            recommendations.append({\n",
    "                'productId': product['_id'],\n",
    "                'name': product['name'],\n",
    "                'category': product['category'],\n",
    "                'price': product['price'],\n",
    "                'similarity_score': float(sim_scores[idx])\n",
    "            })\n",
    "        \n",
    "        return recommendations\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test the function\n",
    "if len(df) > 0:\n",
    "    test_product_id = df.iloc[0]['_id']\n",
    "    test_recommendations = get_recommendations(test_product_id, 5)\n",
    "    \n",
    "    print(f\"Recommendations for product '{df.iloc[0]['name']}':\")\n",
    "    for i, rec in enumerate(test_recommendations, 1):\n",
    "        print(f\"{i}. {rec['name']} (similarity: {rec['similarity_score']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27d608",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate recommendation quality\n",
    "def evaluate_recommendations():\n",
    "    \"\"\"Evaluate the quality of recommendations\"\"\"\n",
    "    category_matches = []\n",
    "    subcategory_matches = []\n",
    "    similarity_scores = []\n",
    "    \n",
    "    # Sample 20 products for evaluation\n",
    "    sample_products = df.sample(min(20, len(df)))\n",
    "    \n",
    "    for _, product in sample_products.iterrows():\n",
    "        recommendations = get_recommendations(product['_id'], 5)\n",
    "        \n",
    "        if recommendations:\n",
    "            # Check category matches\n",
    "            cat_matches = sum(1 for rec in recommendations \n",
    "                            if df[df['_id'] == rec['productId']]['category'].iloc[0] == product['category'])\n",
    "            category_matches.append(cat_matches / len(recommendations))\n",
    "            \n",
    "            # Check subcategory matches\n",
    "            subcat_matches = sum(1 for rec in recommendations \n",
    "                               if df[df['_id'] == rec['productId']]['subCategory'].iloc[0] == product['subCategory'])\n",
    "            subcategory_matches.append(subcat_matches / len(recommendations))\n",
    "            \n",
    "            # Average similarity\n",
    "            avg_sim = np.mean([rec['similarity_score'] for rec in recommendations])\n",
    "            similarity_scores.append(avg_sim)\n",
    "    \n",
    "    results = {\n",
    "        'avg_category_match': np.mean(category_matches),\n",
    "        'avg_subcategory_match': np.mean(subcategory_matches),\n",
    "        'avg_similarity': np.mean(similarity_scores)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "if len(df) > 0:\n",
    "    eval_results = evaluate_recommendations()\n",
    "    print(\"Recommendation Quality Metrics:\")\n",
    "    print(f\"Average Category Match: {eval_results['avg_category_match']:.3f}\")\n",
    "    print(f\"Average Subcategory Match: {eval_results['avg_subcategory_match']:.3f}\")\n",
    "    print(f\"Average Similarity Score: {eval_results['avg_similarity']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590507e",
   "metadata": {},
   "source": [
    "## 7. Advanced Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27daec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for dimensionality reduction and visualization\n",
    "pca = PCA(n_components=2)\n",
    "tfidf_2d = pca.fit_transform(tfidf_matrix.toarray())\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(tfidf_2d[:, 0], tfidf_2d[:, 1], \n",
    "                     c=df['category'].astype('category').cat.codes, \n",
    "                     alpha=0.6, s=50)\n",
    "plt.title('Product Clustering in 2D TF-IDF Space')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.colorbar(scatter, label='Category')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total variance explained: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e838430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering\n",
    "n_clusters = min(5, len(df))\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(tfidf_matrix)\n",
    "\n",
    "df['cluster'] = clusters\n",
    "\n",
    "# Visualize clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(tfidf_2d[:, 0], tfidf_2d[:, 1], \n",
    "                     c=clusters, alpha=0.6, s=50, cmap='viridis')\n",
    "plt.title('K-means Clustering of Products')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Cluster analysis\n",
    "print(\"\\nCluster Analysis:\")\n",
    "for cluster_id in range(n_clusters):\n",
    "    cluster_products = df[df['cluster'] == cluster_id]\n",
    "    print(f\"\\nCluster {cluster_id} ({len(cluster_products)} products):\")\n",
    "    print(f\"  Categories: {cluster_products['category'].value_counts().to_dict()}\")\n",
    "    print(f\"  Avg Price: {cluster_products['price'].mean():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef27a4",
   "metadata": {},
   "source": [
    "## 8. Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models and data\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "# Save vectorizer\n",
    "with open('../models/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "# Save similarity matrix\n",
    "np.save('../models/cosine_similarity_matrix.npy', cosine_sim)\n",
    "\n",
    "# Save processed dataframe\n",
    "df.to_csv('../data/processed_products.csv', index=False)\n",
    "\n",
    "# Save evaluation results\n",
    "if len(df) > 0:\n",
    "    with open('../models/evaluation_results.json', 'w') as f:\n",
    "        json.dump(eval_results, f, indent=2)\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'num_products': len(df),\n",
    "    'num_features': len(feature_names),\n",
    "    'categories': df['category'].unique().tolist(),\n",
    "    'model_type': 'content_based_tfidf',\n",
    "    'evaluation_metrics': eval_results if len(df) > 0 else None\n",
    "}\n",
    "\n",
    "with open('../models/model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"Models and data saved successfully!\")\n",
    "print(f\"Files saved in:\")\n",
    "print(f\"  - ../models/tfidf_vectorizer.pkl\")\n",
    "print(f\"  - ../models/cosine_similarity_matrix.npy\")\n",
    "print(f\"  - ../data/processed_products.csv\")\n",
    "print(f\"  - ../models/evaluation_results.json\")\n",
    "print(f\"  - ../models/model_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c4e3fb",
   "metadata": {},
   "source": [
    "## 9. Production Deployment Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c602a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate production-ready code\n",
    "production_code = '''\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class OptimizedRecommendationEngine:\n",
    "    def __init__(self, model_path=\"models/\"):\n",
    "        self.model_path = model_path\n",
    "        self.vectorizer = None\n",
    "        self.similarity_matrix = None\n",
    "        self.products_df = None\n",
    "        self.load_models()\n",
    "    \n",
    "    def load_models(self):\n",
    "        \"\"\"Load pre-trained models\"\"\"\n",
    "        try:\n",
    "            # Load vectorizer\n",
    "            with open(f\"{self.model_path}tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "                self.vectorizer = pickle.load(f)\n",
    "            \n",
    "            # Load similarity matrix\n",
    "            self.similarity_matrix = np.load(f\"{self.model_path}cosine_similarity_matrix.npy\")\n",
    "            \n",
    "            # Load products data\n",
    "            self.products_df = pd.read_csv(f\"{self.model_path}../data/processed_products.csv\")\n",
    "            \n",
    "            print(f\"Models loaded successfully! {len(self.products_df)} products ready.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading models: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_recommendations(self, product_id, num_recommendations=5):\n",
    "        \"\"\"Get recommendations using pre-computed similarity matrix\"\"\"\n",
    "        try:\n",
    "            # Find product index\n",
    "            product_idx = self.products_df[self.products_df['_id'] == product_id].index\n",
    "            if len(product_idx) == 0:\n",
    "                return []\n",
    "            \n",
    "            product_idx = product_idx[0]\n",
    "            \n",
    "            # Get similarity scores from pre-computed matrix\n",
    "            sim_scores = self.similarity_matrix[product_idx]\n",
    "            \n",
    "            # Get similar products (excluding the product itself)\n",
    "            similar_indices = sim_scores.argsort()[::-1][1:num_recommendations+1]\n",
    "            \n",
    "            recommendations = []\n",
    "            for idx in similar_indices:\n",
    "                product = self.products_df.iloc[idx]\n",
    "                recommendations.append({\n",
    "                    'productId': product['_id'],\n",
    "                    'name': product['name'],\n",
    "                    'category': product['category'],\n",
    "                    'price': product['price'],\n",
    "                    'similarity_score': float(sim_scores[idx])\n",
    "                })\n",
    "            \n",
    "            return recommendations\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting recommendations: {e}\")\n",
    "            return []\n",
    "'''\n",
    "\n",
    "# Save production code\n",
    "with open('../optimized_engine.py', 'w') as f:\n",
    "    f.write(production_code)\n",
    "\n",
    "print(\"Production code generated: ../optimized_engine.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f6d5ea",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "1. ✅ Loaded and analyzed e-commerce product data\n",
    "2. ✅ Created content-based features using TF-IDF\n",
    "3. ✅ Built recommendation system with cosine similarity\n",
    "4. ✅ Evaluated recommendation quality\n",
    "5. ✅ Performed clustering analysis\n",
    "6. ✅ Saved models for production use\n",
    "7. ✅ Generated optimized production code\n",
    "\n",
    "The trained models are ready for deployment in the Flask API!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
